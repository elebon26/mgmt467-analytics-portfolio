{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elebon26/mgmt467-analytics-portfolio/blob/main/Labs/Unit1/(Completed)_Lab_VertexAI_BigQuery_PromptsOnly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ecd5d16",
      "metadata": {
        "id": "4ecd5d16"
      },
      "source": [
        "# Lab: Vertex AI–Assisted BigQuery Analytics — Example Prompts\n",
        "**Goal:** Practice moving from simple SQL to complex analytics in BigQuery using *only* carefully engineered prompts with Vertex AI (Gemini).  \n",
        "**Important:** This notebook contains **prompts only** (no starter code). Paste the prompts into **Vertex AI Studio**, **Vertex AI in Colab Enterprise**, or your chosen chat interface, and then run the generated SQL directly in **BigQuery**. If you decide to automate later, you can ask Vertex AI to convert the winning SQL into a Colab pipeline."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8a8d5cd",
      "metadata": {
        "id": "b8a8d5cd"
      },
      "source": [
        "## How to use this prompts-only notebook\n",
        "1. Open **Vertex AI Studio** (or Gemini in Colab Enterprise chat panel).  \n",
        "2. Copy a prompt from this notebook and paste it into the model. Do **not** paste any code from here; let the model generate it.  \n",
        "3. Run the generated SQL in **BigQuery** (Console → BigQuery Studio).  \n",
        "4. Iterate: refine the prompt when results aren’t what you expect.  \n",
        "5. Document: capture your final SQL, plus a one-sentence takeaway, in your notes/README."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e967d4a7",
      "metadata": {
        "id": "e967d4a7"
      },
      "source": [
        "## Dataset assumptions\n",
        "Use one of these sources (adjust table paths accordingly):\n",
        "- **Global Superstore (Kaggle)** loaded into BigQuery (e.g., `[YOUR_PROJECT].superstore_data.sales`)  \n",
        "- **TheLook eCommerce** public dataset: `bigquery-public-data.thelook_ecommerce`  \n",
        "If you are using *Global Superstore*, make sure column names match your schema (e.g., `Order_Date`, `Region`, `Category`, `Sub_Category`, `Sales`, `Profit`, `Discount`, `State`, `Customer_ID`, `Ship_Mode`)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5940720",
      "metadata": {
        "id": "f5940720"
      },
      "source": [
        "---\n",
        "## Prompting guardrails (quick checklist)\n",
        "- **Be explicit**: table path, column names, filters, output columns, sort order, and limits.  \n",
        "- **Ask for runnable SQL**: “Return a BigQuery SQL block only.”  \n",
        "- **Control cost**: ask for `LIMIT` during exploration and remove it for the final run.  \n",
        "- **Validate**: request a brief explanation of why each clause is present and how you can sanity-check results.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "deGHQK9Tm7Rq"
      },
      "id": "deGHQK9Tm7Rq"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the Google Cloud BigQuery client library\n",
        "!pip install google-cloud-bigquery==3.17.0 pandas==2.1.4\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C75yp0ekYtNl"
      },
      "id": "C75yp0ekYtNl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Authenticate your Colab environment\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('Authenticated')"
      ],
      "metadata": {
        "id": "Q4RLzLk7QqWZ"
      },
      "id": "Q4RLzLk7QqWZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy Schema to a dataframe"
      ],
      "metadata": {
        "id": "jxAyMbWZnEe0"
      },
      "id": "jxAyMbWZnEe0"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "\n",
        "# Replace with your Google Cloud Project ID\n",
        "project_id = 'mgmt-467-1234' # This is derived from your provided table name\n",
        "dataset_id = 'lab1_foundation'\n",
        "table_id = 'superstore'\n",
        "\n",
        "# Construct a BigQuery client object.\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "# Get the table object\n",
        "table_ref = client.dataset(dataset_id).table(table_id)\n",
        "table = client.get_table(table_ref)\n",
        "\n",
        "# Extract schema information\n",
        "schema_list = []\n",
        "for field in table.schema:\n",
        "    schema_list.append({\n",
        "        'name': field.name,\n",
        "        'field_type': field.field_type,\n",
        "        'mode': field.mode,\n",
        "        'description': field.description\n",
        "    })\n",
        "\n",
        "# Convert to Pandas DataFrame\n",
        "schema_df = pd.DataFrame(schema_list)\n",
        "\n",
        "# Display the schema DataFrame (optional, for verification)\n",
        "print(\"Schema DataFrame created:\")\n",
        "# To see the output, run the code.\n"
      ],
      "metadata": {
        "id": "Pdp4EpOIY93w"
      },
      "id": "Pdp4EpOIY93w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLean Column Names"
      ],
      "metadata": {
        "id": "QkdVGvHZnNNn"
      },
      "id": "QkdVGvHZnNNn"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Clean the Column Names ---\n",
        "# Create a 'clean_name' column with standard naming conventions:\n",
        "# lowercase, with spaces and hyphens replaced by underscores.\n",
        "schema_df['clean_name'] = schema_df['name'].str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
        "\n",
        "\n",
        "# --- 2. Generate the Aliases for the SELECT Clause ---\n",
        "column_expressions = []\n",
        "for index, row in schema_df.iterrows():\n",
        "    original_name = row['name']\n",
        "    clean_name = row['clean_name']\n",
        "\n",
        "    # If the original name contains a space or special character, it needs to be\n",
        "    # enclosed in backticks (`) in the SQL statement.\n",
        "    if ' ' in original_name or '-' in original_name:\n",
        "        expression = f'`{original_name}` AS {clean_name}'\n",
        "    else:\n",
        "        # If the name is already clean, we still alias it for consistency.\n",
        "        expression = f'{original_name} AS {clean_name}'\n",
        "    column_expressions.append(expression)\n",
        "\n",
        "# Join all the individual column expressions into a single, formatted string.\n",
        "select_clause = \",\\n  \".join(column_expressions)\n",
        "\n",
        "\n",
        "# --- 3. Construct the Final CREATE VIEW Statement ---\n",
        "new_view_id = 'superstore_clean' # You can change this if you like\n",
        "\n",
        "create_view_sql = f\"\"\"\n",
        "CREATE OR REPLACE VIEW `{project_id}.{dataset_id}.{new_view_id}` AS\n",
        "SELECT\n",
        "  {select_clause}\n",
        "FROM\n",
        "  `{project_id}.{dataset_id}.{table_id}`;\n",
        "\"\"\"\n",
        "\n",
        "# --- 4. Print the Final SQL ---\n",
        "print(\"--- Copy the SQL below and run it in your BigQuery Console ---\")\n",
        "print(create_view_sql)"
      ],
      "metadata": {
        "id": "hjxWwOPYgyu3"
      },
      "id": "hjxWwOPYgyu3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate View with standard column naming convention"
      ],
      "metadata": {
        "id": "Av6ZsQoIhw7v"
      },
      "id": "Av6ZsQoIhw7v"
    },
    {
      "cell_type": "code",
      "source": [
        "# Execute the CREATE VIEW SQL query\n",
        "try:\n",
        "    query_job = client.query(create_view_sql)  # API request\n",
        "    query_job.result()  # Waits for the query to finish\n",
        "    print(f\"View '{new_view_id}' created/replaced successfully in dataset '{dataset_id}'.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while creating the view: {e}\")\n",
        "\n",
        "# Now, let's print 10 rows from the newly created view to verify\n",
        "print(f\"\\n--- First 10 rows from the new view '{new_view_id}' ---\")\n",
        "try:\n",
        "    # Construct a reference to the new view\n",
        "    view_table_ref = client.dataset(dataset_id).table(new_view_id)\n",
        "\n",
        "    # Fetch the first 10 rows\n",
        "    rows = client.list_rows(view_table_ref, max_results=10)\n",
        "\n",
        "    # Print header\n",
        "    print(\" | \".join([field.name for field in rows.schema]))\n",
        "    print(\"-\" * 80) # Separator\n",
        "\n",
        "    # Print rows\n",
        "    for row in rows:\n",
        "        print(\" | \".join([str(item) for item in row.values()]))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while fetching rows from the view: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xoMmfxY2hOOg"
      },
      "id": "xoMmfxY2hOOg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This assumes your 'client' object from the previous cell is still active\n",
        "# and correctly authenticated.\n",
        "\n",
        "print(\"✅ Step 1: Defining the query string...\")\n",
        "\n",
        "query_string = \"\"\"\n",
        "SELECT\n",
        "  order_id,\n",
        "  customer_name,\n",
        "  product_name,\n",
        "  sales,\n",
        "  profit\n",
        "FROM\n",
        "  `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "print(\"✅ Step 2: Sending the query to BigQuery. This may take a moment...\")\n",
        "\n",
        "# Use a try-except block to catch potential errors\n",
        "try:\n",
        "    query_job = client.query(query_string)\n",
        "\n",
        "    print(\"✅ Step 3: Waiting for query to complete and fetching results...\")\n",
        "    results_df = query_job.to_dataframe()\n",
        "\n",
        "    print(f\"✅ Step 4: Query finished. Found {len(results_df)} rows.\")\n",
        "\n",
        "    if results_df.empty:\n",
        "        print(\"\\n⚠️ The query ran successfully but returned an empty result. Please double-check that your 'superstore_clean' view exists and the original table has data.\")\n",
        "    else:\n",
        "        print(\"\\n--- Displaying Results ---\")\n",
        "        display(results_df)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ An error occurred: {e}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "BDjVOddXjBvS"
      },
      "id": "BDjVOddXjBvS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I-aQV1fUlLsh"
      },
      "id": "I-aQV1fUlLsh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vpNaruc0gxgO"
      },
      "id": "vpNaruc0gxgO"
    },
    {
      "cell_type": "markdown",
      "id": "21fdd1b4",
      "metadata": {
        "id": "21fdd1b4"
      },
      "source": [
        "## Part A — SQL Warm‑Up (SELECT, WHERE, ORDER BY, LIMIT, DISTINCT)\n",
        "**Aim:** Build confidence with precise, unambiguous prompts that yield clean, runnable SQL."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d51345cd",
      "metadata": {
        "id": "d51345cd"
      },
      "source": [
        "### A1. Unique values (DISTINCT)\n",
        "**Prompt (paste in Vertex AI):**\n",
        "```\n",
        "Act as a senior BigQuery analyst. Produce a **single runnable BigQuery SQL** (no commentary) for:\n",
        "- Task: List all unique `Sub_Category` values sold in the 'West' region.\n",
        "- Table: `mgmt-467-47888.lab1_foundation.superstore`\n",
        "- Filter: `Region = 'West'`\n",
        "- Output: a single column named `Sub_Category`\n",
        "- Sort: alphabetically A→Z\n",
        "- Add: `LIMIT 100` to control cost during exploration.\n",
        "```\n",
        "**Reflection:** Did the result match your expectations? If not, what ambiguity in your prompt might have caused the mismatch?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes of the most part the outcome did match my expectation but adding more specificity to the expected output in the prompt could have helped enhance the answer."
      ],
      "metadata": {
        "id": "P-jhZd0JbZbJ"
      },
      "id": "P-jhZd0JbZbJ"
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "    DISTINCT `Sub-Category` AS Sub_Category\n",
        "FROM\n",
        "    `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "WHERE\n",
        "    Region = 'West'\n",
        "ORDER BY\n",
        "    Sub_Category ASC\n",
        "LIMIT 100\n",
        "\"\"\"\n",
        "results_df = query_job.to_dataframe()\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "FIjfmUFEiMA4"
      },
      "id": "FIjfmUFEiMA4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d6d69d23",
      "metadata": {
        "id": "d6d69d23"
      },
      "source": [
        "### A2. Top‑N by metric (ORDER BY … DESC)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Return the top 10 customers by total profit.\n",
        "Table: `mgmt-467-47888.lab_foundation.superstore`\n",
        "Columns used: `Customer_ID`, `Profit`\n",
        "Output columns: `Customer_ID`, `total_profit`\n",
        "Logic: SUM Profit per customer, order by `total_profit` DESC\n",
        "Add `LIMIT 10`.\n",
        "```\n",
        "**Tip:** If your schema uses different identifiers (e.g., `Customer Name`), restate column names explicitly."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "    Customer_ID,\n",
        "    SUM(Profit) AS total_profit\n",
        "FROM\n",
        "    `mgmt-467-1234.lab_foundation.superstore`\n",
        "GROUP BY\n",
        "    Customer_ID\n",
        "ORDER BY\n",
        "    total_profit DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "results_df = query_job.to_dataframe()\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "IgmOpy67aCAF"
      },
      "id": "IgmOpy67aCAF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f4a477d4",
      "metadata": {
        "id": "f4a477d4"
      },
      "source": [
        "### A3. Basic filtering (WHERE) + sanity checks\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Count orders shipped with each `Ship_Mode`, but only for orders in the 'Technology' category.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Output: `Ship_Mode`, `order_count`\n",
        "Logic: COUNT(*) grouped by `Ship_Mode`\n",
        "Sort by `order_count` DESC\n",
        "```\n",
        "**Validation ask:** “Also list two quick sanity checks to verify the numbers.”"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "    ship_mode,\n",
        "    COUNT(*) AS order_count\n",
        "FROM\n",
        "    `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "WHERE\n",
        "    category = 'Technology'\n",
        "GROUP BY\n",
        "    ship_mode\n",
        "ORDER BY\n",
        "    order_count DESC;\n",
        "\"\"\"\n",
        "results_df = query_job.to_dataframe()\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "PxCgO4A9ahX8"
      },
      "id": "PxCgO4A9ahX8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "51afdc05",
      "metadata": {
        "id": "51afdc05"
      },
      "source": [
        "## Part B — Grouped Analytics (GROUP BY, HAVING)\n",
        "**Aim:** Turn raw facts into grouped metrics and filtered aggregations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10c5933e",
      "metadata": {
        "id": "10c5933e"
      },
      "source": [
        "### B1. KPI aggregation with WHERE + GROUP BY\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Compute monthly revenue for the last 12 full months.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Assume: `Order_Date` is a DATE or TIMESTAMP column named exactly `Order_Date`.\n",
        "Output: `year_month` (YYYY-MM format), `monthly_revenue`\n",
        "Logic: Truncate date to month, SUM `Sales`, filter to last 12 full months.\n",
        "Sort by `year_month` ascending.\n",
        "Include a `LIMIT` safeguard for exploration.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "  FORMAT_DATE('%Y-%m', DATE_TRUNC(Order_Date, MONTH)) AS year_month,\n",
        "  SUM(Sales) AS monthly_revenue\n",
        "FROM\n",
        "  `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "WHERE\n",
        "  DATE_TRUNC(Order_Date, MONTH) BETWEEN DATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 12 MONTH), MONTH)\n",
        "                                     AND DATE_TRUNC(DATE_SUB(CURRENT_DATE(), INTERVAL 1 MONTH), MONTH)\n",
        "GROUP BY\n",
        "  year_month\n",
        "ORDER BY\n",
        "  year_month ASC\n",
        "LIMIT 100;\n",
        "\"\"\"\n",
        "\n",
        "results_df = query_job.to_dataframe()\n",
        "display(results_df)"
      ],
      "metadata": {
        "id": "Ra13_OnAb6kl"
      },
      "id": "Ra13_OnAb6kl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "15d75d03",
      "metadata": {
        "id": "15d75d03"
      },
      "source": [
        "### B2. Post‑aggregation filter (HAVING)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Find sub-categories whose total profit over the entire dataset is negative.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Output: `Sub_Category`, `total_profit`\n",
        "Logic: SUM `Profit` GROUP BY `Sub_Category`, HAVING SUM(Profit) < 0\n",
        "Sort by `total_profit` ASC (most negative first).\n",
        "```\n",
        "**Why HAVING?** Ask the model to include a 1-sentence explanation of why HAVING is used instead of WHERE here."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "  Sub_Category,\n",
        "  SUM(Profit) AS total_profit\n",
        "FROM\n",
        "  `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "GROUP BY\n",
        "  Sub_Category\n",
        "HAVING\n",
        "  SUM(Profit) < 0\n",
        "ORDER BY\n",
        "  total_profit ASC;\n",
        "\"\"\"\n",
        "\n",
        "results_df = query_job.to_dataframe()\n",
        "display(results_df)\n"
      ],
      "metadata": {
        "id": "cmtGDMgJb_Kw"
      },
      "id": "cmtGDMgJb_Kw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AbeJDhENtPmV"
      },
      "id": "AbeJDhENtPmV"
    },
    {
      "cell_type": "markdown",
      "id": "bbd28071",
      "metadata": {
        "id": "bbd28071"
      },
      "source": [
        "## Part C — Joins (dimension enrichment)\n",
        "**Aim:** Use joins to enhance facts with attributes."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7736534",
      "metadata": {
        "id": "e7736534"
      },
      "source": [
        "### C1. Join facts to a small dimension\n",
        "*(If you have a customer or product dimension in your schema, use it. Otherwise, request a synthetic example.)*  \n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Join the sales table to a product dimension to report `Product_ID`, `Product_Name`, and total sales.\n",
        "Tables: `[YOUR_PROJECT].superstore_data.sales` as s, `[YOUR_PROJECT].superstore_data.products` as p\n",
        "Join key: `s.Product_ID = p.Product_ID`\n",
        "Output: `Product_ID`, `Product_Name`, `total_sales`\n",
        "Sort by `total_sales` DESC\n",
        "```\n",
        "**If you lack a dimension table:** Ask the model how to simulate one temporarily via a CTE."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_string = \"\"\"\n",
        "SELECT\n",
        "  s.Product_ID,\n",
        "  p.Product_Name,\n",
        "  SUM(s.Sales) AS total_sales\n",
        "FROM\n",
        "  `mgmt-467-1234.lab1_foundation.superstore_clean` AS s\n",
        "JOIN\n",
        "  `mgmt-467-1234.lab1_foundation.superstore_products` AS p\n",
        "ON\n",
        "  s.Product_ID = p.Product_ID\n",
        "GROUP BY\n",
        "  s.Product_ID, p.Product_Name\n",
        "ORDER BY\n",
        "  total_sales DESC;\n",
        "\"\"\"\n",
        "\n",
        "results_df = query_job.to_dataframe()\n",
        "display(results_df)\n"
      ],
      "metadata": {
        "id": "zMKu0JotcE8u"
      },
      "id": "zMKu0JotcE8u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xmkgogMgwsBK"
      },
      "id": "xmkgogMgwsBK"
    },
    {
      "cell_type": "markdown",
      "id": "dca07c5a",
      "metadata": {
        "id": "dca07c5a"
      },
      "source": [
        "## Part D — Common Table Expressions (CTEs)\n",
        "**Aim:** Make complex logic readable and testable in steps."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b268567f",
      "metadata": {
        "id": "b268567f"
      },
      "source": [
        "### D1. Multi‑step ranking with CTEs\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Goal: Within each `Region`, rank states by total sales and return top 3 per region.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "CTE 1 (`state_sales`): SUM(Sales) by `Region`, `State`\n",
        "CTE 2 (`ranked_state_sales`): Add `RANK() OVER (PARTITION BY Region ORDER BY total_sales DESC)` as `sales_rank`\n",
        "Final SELECT: rows where `sales_rank <= 3`\n",
        "Output columns: `Region`, `State`, `total_sales`, `sales_rank`\n",
        "Sort: by `Region`, then `sales_rank`\n",
        "```\n",
        "**Ask for**: a one-paragraph explanation of each step, then **provide only the final runnable SQL**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This SQL query identifies the top 3 states by total sales within each region using two Common Table Expressions (CTEs). The first CTE, state_sales, aggregates the total sales for each unique combination of region and state. The second CTE, ranked_state_sales, then applies the RANK() window function to these aggregated sales. RANK() is partitioned by region to ensure independent ranking within each region and ordered by total_sales in descending order to assign higher ranks to states with greater sales. Finally, the main SELECT statement filters the results from ranked_state_sales to include only those states whose sales_rank is 3 or less, thereby showing only the top 3 states per region, and orders the output by region and then by sales rank for clarity."
      ],
      "metadata": {
        "id": "LeZ0AMUAP2Oq"
      },
      "id": "LeZ0AMUAP2Oq"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%bigquery\n",
        "WITH\n",
        "  state_sales AS (\n",
        "  SELECT\n",
        "    region,\n",
        "    state,\n",
        "    SUM(sales) AS total_sales\n",
        "  FROM\n",
        "    `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "  GROUP BY\n",
        "    region,\n",
        "    state\n",
        "),\n",
        "  ranked_state_sales AS (\n",
        "  SELECT\n",
        "    region,\n",
        "    state,\n",
        "    total_sales,\n",
        "    RANK() OVER (PARTITION BY region ORDER BY total_sales DESC) AS sales_rank\n",
        "  FROM\n",
        "    state_sales\n",
        ")\n",
        "SELECT\n",
        "  region,\n",
        "  state,\n",
        "  total_sales,\n",
        "  sales_rank\n",
        "FROM\n",
        "  ranked_state_sales\n",
        "WHERE\n",
        "  sales_rank <= 3\n",
        "ORDER BY\n",
        "  region,\n",
        "  sales_rank;"
      ],
      "metadata": {
        "id": "eb1wieE9PX4d"
      },
      "id": "eb1wieE9PX4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "46a39db5",
      "metadata": {
        "id": "46a39db5"
      },
      "source": [
        "### D2. Time‑boxed “most improved” analysis\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Goal: Identify the top 5 sub-categories with the largest YoY revenue increase from 2023 to 2024.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "CTE `yr_sales`: SUM(Sales) by `Sub_Category` and `year` extracted from `Order_Date`\n",
        "Final: pivot or self-join to compute delta (2024 minus 2023) as `yoy_delta`\n",
        "Output: `Sub_Category`, `sales_2023`, `sales_2024`, `yoy_delta`\n",
        "Order by `yoy_delta` DESC\n",
        "Limit 5\n",
        "```\n",
        "**Validation:** Ask the model for two quick failure modes (e.g., missing years) and how to handle them."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This SQL query identifies the top 5 sub-categories with the largest Year-over-Year (YoY) revenue increase from 2023 to 2024. It utilizes a Common Table Expression (CTE) named yearly_sales to first aggregate the total sales for each sub-category per year. Then, it performs a self-join on this CTE to bring together the 2023 and 2024 sales figures for each sub-category. Finally, it calculates the yoy_delta by subtracting 2023 sales from 2024 sales, orders the results by this delta in descending order, and limits the output to the top 5 entries.\n",
        "\n",
        "Validation:\n",
        "\n",
        "Missing Years for a Sub-Category: A potential failure mode is when a sub-category has sales in one of the years (e.g., 2024) but not the other (e.g., 2023). In the current setup, such sub-categories would be excluded due to the JOIN condition requiring a match for both years. To handle this, you could use a FULL OUTER JOIN instead of an INNER JOIN, and then use COALESCE(yearly_sales.total_sales, 0) for sales_2023 and sales_2024 to treat missing year's sales as zero.\n",
        "\n",
        "No Data for Either 2023 or 2024 Entirely: If the underlying table superstore_clean completely lacks data for either 2023 or 2024, the yearly_sales CTE for that specific year will be empty, leading to an empty result set in the final output. You can guard against this by checking the existence of data for both years using COUNT(*) in separate queries or CTEs before attempting the main calculation. Alternatively, if a null result is acceptable, no explicit handling is required."
      ],
      "metadata": {
        "id": "X4ciG89JQzv9"
      },
      "id": "X4ciG89JQzv9"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery\n",
        "WITH\n",
        "  yearly_sales AS (\n",
        "  SELECT\n",
        "    sub_category,\n",
        "    EXTRACT(YEAR FROM order_date) AS sales_year,\n",
        "    SUM(sales) AS total_sales\n",
        "  FROM\n",
        "    `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "  WHERE\n",
        "    EXTRACT(YEAR FROM order_date) IN (2023, 2024)\n",
        "  GROUP BY\n",
        "    sub_category,\n",
        "    sales_year\n",
        ")\n",
        "SELECT\n",
        "  ys_2024.sub_category,\n",
        "  ys_2023.total_sales AS sales_2023,\n",
        "  ys_2024.total_sales AS sales_2024,\n",
        "  (ys_2024.total_sales - ys_2023.total_sales) AS yoy_delta\n",
        "FROM\n",
        "  yearly_sales AS ys_2024\n",
        "JOIN\n",
        "  yearly_sales AS ys_2023\n",
        "ON\n",
        "  ys_2024.sub_category = ys_2023.sub_category\n",
        "WHERE\n",
        "  ys_2024.sales_year = 2024\n",
        "  AND ys_2023.sales_year = 2023\n",
        "ORDER BY\n",
        "  yoy_delta DESC\n",
        "LIMIT 5;"
      ],
      "metadata": {
        "id": "FUmAgS0OQJXl"
      },
      "id": "FUmAgS0OQJXl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c776dd89",
      "metadata": {
        "id": "c776dd89"
      },
      "source": [
        "## Part E — Window Functions (ROW_NUMBER, RANK, DENSE_RANK, LAG/LEAD, moving averages)\n",
        "**Aim:** Compare rows across partitions and time; compute trends and ranks without collapsing rows."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a5cf0c4",
      "metadata": {
        "id": "6a5cf0c4"
      },
      "source": [
        "### E1. Top product per region (ROW_NUMBER)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: For each `Region`, return only the single highest-revenue `Sub_Category`.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "CTE `subcat_sales`: SUM(Sales) by `Region`, `Sub_Category`\n",
        "Add `ROW_NUMBER() OVER (PARTITION BY Region ORDER BY total_sales DESC)` as rn\n",
        "Final: filter `rn = 1`\n",
        "Output: `Region`, `Sub_Category`, `total_sales`\n",
        "Sort by `Region`\n",
        "```\n",
        "**Why `ROW_NUMBER` instead of `RANK`?** Ask the model to add a 2-sentence contrast."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas_gbq\n",
        "\n",
        "project_id = 'mgmt-467-1234'\n",
        "\n",
        "sql = \"\"\"\n",
        "WITH subcat_sales AS (\n",
        "  SELECT\n",
        "    region,\n",
        "    sub_category,\n",
        "    SUM(sales) AS total_sales\n",
        "  FROM\n",
        "    `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "  GROUP BY\n",
        "    region,\n",
        "    sub_category\n",
        ")\n",
        "SELECT\n",
        "  region,\n",
        "  sub_category,\n",
        "  total_sales\n",
        "FROM\n",
        "  (\n",
        "    SELECT\n",
        "      region,\n",
        "      sub_category,\n",
        "      total_sales,\n",
        "      ROW_NUMBER() OVER (PARTITION BY region ORDER BY total_sales DESC) AS rn\n",
        "    FROM\n",
        "      subcat_sales\n",
        "  )\n",
        "WHERE\n",
        "  rn = 1\n",
        "ORDER BY\n",
        "  region;\n",
        "\"\"\"\n",
        "\n",
        "df = pandas_gbq.read_gbq(sql, project_id=project_id, dialect=\"standard\")\n",
        "df"
      ],
      "metadata": {
        "id": "YAYKEqe6SOv9"
      },
      "id": "YAYKEqe6SOv9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When you use ROW_NUMBER(), each row within a partition gets a unique, sequential number, even if there are ties in the ordering column. In contrast, RANK() assigns the same rank to rows that have identical values in the ordering column, and then skips the next rank numbers, which can create gaps in the ranking sequence."
      ],
      "metadata": {
        "id": "9bTHUtSxScVg"
      },
      "id": "9bTHUtSxScVg"
    },
    {
      "cell_type": "markdown",
      "id": "552eb898",
      "metadata": {
        "id": "552eb898"
      },
      "source": [
        "### E2. YoY growth with LAG\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: Compute year-over-year revenue growth for 'Phones' sub-category.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Steps:\n",
        "- Filter to `Sub_Category = 'Phones'`\n",
        "- Aggregate yearly revenue using EXTRACT(YEAR FROM Order_Date)\n",
        "- Add `LAG(yearly_revenue) OVER (ORDER BY year)` as `prev_revenue`\n",
        "- Compute `yoy_pct = 100.0 * (yearly_revenue - prev_revenue) / prev_revenue`\n",
        "Output: `year`, `yearly_revenue`, `prev_revenue`, `yoy_pct`\n",
        "Sort by `year` ASC\n",
        "```\n",
        "**Ask for**: a guard against divide-by-zero or NULL previous year."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas_gbq\n",
        "\n",
        "project_id = 'mgmt-467-1234'\n",
        "\n",
        "sql = \"\"\"\n",
        "WITH yearly_revenue_data AS (\n",
        "  SELECT\n",
        "    EXTRACT(YEAR FROM order_date) AS year,\n",
        "    SUM(sales) AS yearly_revenue\n",
        "  FROM\n",
        "    `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "  WHERE\n",
        "    sub_category = 'Phones'\n",
        "  GROUP BY\n",
        "    year\n",
        "),\n",
        "lagged_revenue AS (\n",
        "  SELECT\n",
        "    year,\n",
        "    yearly_revenue,\n",
        "    LAG(yearly_revenue) OVER (ORDER BY year) AS prev_revenue\n",
        "  FROM\n",
        "    yearly_revenue_data\n",
        ")\n",
        "SELECT\n",
        "  year,\n",
        "  yearly_revenue,\n",
        "  prev_revenue,\n",
        "  CASE\n",
        "    WHEN prev_revenue IS NULL OR prev_revenue = 0 THEN NULL\n",
        "    ELSE 100.0 * (yearly_revenue - prev_revenue) / prev_revenue\n",
        "  END AS yoy_pct\n",
        "FROM\n",
        "  lagged_revenue\n",
        "ORDER BY\n",
        "  year ASC;\n",
        "\"\"\"\n",
        "\n",
        "df = pandas_gbq.read_gbq(sql, project_id=project_id, dialect=\"standard\")\n",
        "df"
      ],
      "metadata": {
        "id": "R_8Uz8AtSpdV"
      },
      "id": "R_8Uz8AtSpdV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "ac0c3893",
      "metadata": {
        "id": "ac0c3893"
      },
      "source": [
        "### E3. 3‑month moving average (MA)\n",
        "**Prompt:**\n",
        "```\n",
        "BigQuery SQL only.\n",
        "Task: For the 'Corporate' segment, compute a 3-month moving average of monthly revenue.\n",
        "Table: `[YOUR_PROJECT].superstore_data.sales`\n",
        "Steps:\n",
        "- Derive `month` via DATE_TRUNC(Order_Date, MONTH)\n",
        "- SUM(Sales) per `month`\n",
        "- Add `AVG(monthly_revenue) OVER (ORDER BY month ROWS BETWEEN 2 PRECEDING AND CURRENT ROW)` as `ma_3`\n",
        "Output: `month`, `monthly_revenue`, `ma_3`\n",
        "Sort by `month` ASC\n",
        "```\n",
        "**Tip:** Ask the model to include a 1‑line cost control note (e.g., restrict date range while iterating)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas_gbq\n",
        "\n",
        "project_id = 'mgmt-467-1234'\n",
        "\n",
        "sql = \"\"\"\n",
        "WITH monthly_data AS (\n",
        "  SELECT\n",
        "    DATE_TRUNC(order_date, MONTH) AS month,\n",
        "    SUM(sales) AS monthly_revenue\n",
        "  FROM\n",
        "    `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "  WHERE\n",
        "    segment = 'Corporate'\n",
        "    -- Consider adding a date range filter here for cost control during iteration, e.g., AND order_date BETWEEN '2023-01-01' AND '2023-12-31'\n",
        "  GROUP BY\n",
        "    month\n",
        ")\n",
        "SELECT\n",
        "  month,\n",
        "  monthly_revenue,\n",
        "  AVG(monthly_revenue) OVER (ORDER BY month ROWS BETWEEN 2 PRECEDING AND CURRENT ROW) AS ma_3\n",
        "FROM\n",
        "  monthly_data\n",
        "ORDER BY\n",
        "  month ASC;\n",
        "\"\"\"\n",
        "\n",
        "df = pandas_gbq.read_gbq(sql, project_id=project_id, dialect=\"standard\")\n",
        "df"
      ],
      "metadata": {
        "id": "zDXsX14WTMwa"
      },
      "id": "zDXsX14WTMwa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a4e347a6",
      "metadata": {
        "id": "a4e347a6"
      },
      "source": [
        "## Part F — Debugging & Optimization Prompts\n",
        "**Aim:** Use the model as a rubber duck for error handling and performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5d80923",
      "metadata": {
        "id": "e5d80923"
      },
      "source": [
        "### F1. Explain the error, propose a fix\n",
        "**Prompt:**\n",
        "```\n",
        "I ran this BigQuery SQL and got an error:\n",
        "[PASTE ERROR MESSAGE and the exact SQL here]\n",
        "Act as a BigQuery trouble‑shooter.\n",
        "1) Identify the root cause.\n",
        "2) Propose the smallest possible fix.\n",
        "3) Suggest a quick sanity check query to verify the fix.\n",
        "Return only the corrected SQL and a 2‑sentence rationale.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#%%bigquery\n",
        "#SELECT\n",
        "#  order_id, sales\n",
        "#  `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "#LIMIT 5;\n",
        "\n",
        "\n",
        "%%bigquery\n",
        "SELECT\n",
        "  order_id,\n",
        "  sales\n",
        "FROM\n",
        "  `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "LIMIT 5;"
      ],
      "metadata": {
        "id": "1X-LBFOTWBz_"
      },
      "id": "1X-LBFOTWBz_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The root cause of the error was the omission of the `FROM` keyword, which is necessary to specify the data source for the selected columns. The corrected query explicitly includes `FROM` to link the columns `order_id` and `sales` to the `superstore_clean` table, resolving the 'unrecognized name' error.\n"
      ],
      "metadata": {
        "id": "m-EYKg7DZE8_"
      },
      "id": "m-EYKg7DZE8_"
    },
    {
      "cell_type": "markdown",
      "id": "890814f8",
      "metadata": {
        "id": "890814f8"
      },
      "source": [
        "### F2. Reduce cost / improve speed\n",
        "**Prompt:**\n",
        "```\n",
        "Act as a BigQuery cost optimizer.\n",
        "Given this query (below), list 3 ways to reduce scanned bytes and improve performance without changing the business logic.\n",
        "[PASTE YOUR SQL HERE]\n",
        "Prioritize: partition filters, column pruning, pre-aggregations, and temporary results via CTEs.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery\n",
        "SELECT\n",
        "  product_name,\n",
        "  SUM(sales) AS total_sales,\n",
        "  SUM(profit) AS total_profit\n",
        "FROM\n",
        "  `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "GROUP BY\n",
        "  product_name\n",
        "ORDER BY\n",
        "  total_sales DESC\n",
        "LIMIT 100;"
      ],
      "metadata": {
        "id": "t6rqXHLfZ22E"
      },
      "id": "t6rqXHLfZ22E",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "1f88a2f5",
      "metadata": {
        "id": "1f88a2f5"
      },
      "source": [
        "## Part G — Validation & Counter‑examples (DIVE: Validate)\n",
        "**Aim:** Avoid “first‑answer fallacy” by testing alternatives."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ed05c0b",
      "metadata": {
        "id": "2ed05c0b"
      },
      "source": [
        "### G1. Ask for counter‑queries\n",
        "**Prompt:**\n",
        "```\n",
        "I concluded that 'Tables' is a high‑sales but negative‑profit sub-category due to high discounts.\n",
        "Create two alternative BigQuery SQL queries that could falsify or nuance this finding:\n",
        "- One that slices by region and time\n",
        "- One that controls for order priority or ship mode\n",
        "Return BigQuery SQL only, then a one-paragraph note on how to compare outcomes.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery\n",
        "-- Query 1: Slice 'Tables' performance by region and time\n",
        "SELECT\n",
        "  region,\n",
        "  EXTRACT(YEAR FROM order_date) AS order_year,\n",
        "  SUM(sales) AS total_sales,\n",
        "  SUM(profit) AS total_profit,\n",
        "  AVG(discount) AS average_discount\n",
        "FROM\n",
        "  `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "WHERE\n",
        "  sub_category = 'Tables'\n",
        "GROUP BY\n",
        "  region,\n",
        "  order_year\n",
        "ORDER BY\n",
        "  region,\n",
        "  order_year;"
      ],
      "metadata": {
        "id": "1yjzy4ThaJc5"
      },
      "id": "1yjzy4ThaJc5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bigquery\n",
        "-- Query 2: Slice 'Tables' performance by ship mode\n",
        "SELECT\n",
        "  ship_mode,\n",
        "  SUM(sales) AS total_sales,\n",
        "  SUM(profit) AS total_profit,\n",
        "  AVG(discount) AS average_discount\n",
        "FROM\n",
        "  `mgmt-467-1234.lab1_foundation.superstore_clean`\n",
        "WHERE\n",
        "  sub_category = 'Tables'\n",
        "GROUP BY\n",
        "  ship_mode\n",
        "ORDER BY\n",
        "  ship_mode;"
      ],
      "metadata": {
        "id": "9j6-JWUlaRZj"
      },
      "id": "9j6-JWUlaRZj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare outcomes, first, examine the regional and temporal breakdown from the first query. If 'Tables' shows positive profit in certain regions or during specific time periods, it nuances the overall negative-profit finding, suggesting the issue might be localized or a recent development rather than systemic. Second, analyze the results from the second query by ship mode. If negative profits and high discounts for 'Tables' are concentrated in particular shipping methods, it indicates that the shipping strategy or associated costs/discounts for those modes might be the primary driver of unprofitability, rather than the product category itself."
      ],
      "metadata": {
        "id": "22dpCrY2aUmL"
      },
      "id": "22dpCrY2aUmL"
    },
    {
      "cell_type": "markdown",
      "id": "1e108a43",
      "metadata": {
        "id": "1e108a43"
      },
      "source": [
        "## Part H — Synthesis (DIVE: Extend)\n",
        "**Aim:** Turn analysis into business‑ready insights."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0bf2bac2",
      "metadata": {
        "id": "0bf2bac2"
      },
      "source": [
        "### H1. Executive‑style summary\n",
        "**Prompt:**\n",
        "```\n",
        "Act as a business strategist.\n",
        "Based on the following metrics/figures (briefly summarize your results here), write a 4-sentence executive summary:\n",
        "- 1 sentence: what changed and by how much\n",
        "- 1 sentence: why it likely changed (drivers)\n",
        "- 1 sentence: recommended action (who/what/when)\n",
        "- 1 sentence: metric to monitor next\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'Tables' sub-category consistently generated negative profit across all shipping modes, with 'Standard Class' alone accounting for over $11,900 in losses despite being the highest sales contributor, yet this unprofitability is nuanced by regional and temporal performance showing positive profit in some periods and regions with lower discounts. High discounts, particularly associated with 'Standard Class' shipping and consistently observed in the East region, are the most likely drivers of the sub-category's overall negative profitability. The sales and logistics teams should promptly review and adjust the discounting strategy and shipping costs for 'Tables', with a focus on 'Standard Class' deliveries and the East region, aiming for implementation within the next quarter. The key metric to continuously monitor is the net profit margin and average discount percentage for 'Tables' across all regions and shipping modes to track the effectiveness of these strategic changes."
      ],
      "metadata": {
        "id": "RwvHDhVqa6FJ"
      },
      "id": "RwvHDhVqa6FJ"
    },
    {
      "cell_type": "markdown",
      "id": "0148a198",
      "metadata": {
        "id": "0148a198"
      },
      "source": [
        "---\n",
        "## Submission checklist\n",
        "- [ ] Kept prompts precise and reproducible  \n",
        "- [ ] Captured at least **one** CTE query and **one** window function query  \n",
        "- [ ] Documented **two** validation attempts (counter‑queries or alternate slice)  \n",
        "- [ ] Wrote a 4‑sentence executive summary based on results  \n",
        "- [ ] (Optional) Converted final query into a scheduled job\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}