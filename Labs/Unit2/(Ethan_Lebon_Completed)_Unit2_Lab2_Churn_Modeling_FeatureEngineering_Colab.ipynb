{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/elebon26/mgmt467-analytics-portfolio/blob/main/Labs/Unit2/(Ethan_Lebon_Completed)_Unit2_Lab2_Churn_Modeling_FeatureEngineering_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5869f3af",
      "metadata": {
        "id": "5869f3af"
      },
      "source": [
        "# 📊 MGMT 467 - Unit 2 Lab 2: Churn Modeling with BigQueryML + Feature Engineering\n",
        "**Date:** 2025-10-16\n",
        "\n",
        "In this lab you will:\n",
        "- Connect to BigQuery from Colab\n",
        "- Create features and labels\n",
        "- Engineer new features from user behavior\n",
        "- Train and evaluate logistic regression models\n",
        "- Reflect on modeling assumptions and interpret results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "305da483",
      "metadata": {
        "id": "305da483"
      },
      "outputs": [],
      "source": [
        "# ✅ Authenticate and set up GCP project\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "project_id = \"mgmt-467-1234\"  # <-- Replace with your actual project ID\n",
        "!gcloud config set project $project_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08a79119",
      "metadata": {
        "id": "08a79119"
      },
      "outputs": [],
      "source": [
        "# ✅ Verify BigQuery access\n",
        "%%bigquery --project $project_id\n",
        "SELECT CURRENT_DATE() AS today, SESSION_USER() AS user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef5701f",
      "metadata": {
        "collapsed": true,
        "id": "4ef5701f"
      },
      "outputs": [],
      "source": [
        "# ✅ Prepare base churn features\n",
        "%%bigquery --project $project_id\n",
        "CREATE OR REPLACE TABLE `your_dataset.churn_features` AS\n",
        "SELECT\n",
        "  user_id,\n",
        "  region,\n",
        "  plan_tier,\n",
        "  age_band,\n",
        "  avg_rating,\n",
        "  total_minutes,\n",
        "  avg_progress,\n",
        "  num_sessions,\n",
        "  churn_label\n",
        "FROM `your_dataset.cleaned_features`\n",
        "WHERE churn_label IS NOT NULL;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3ce2cc5",
      "metadata": {
        "collapsed": true,
        "id": "a3ce2cc5"
      },
      "outputs": [],
      "source": [
        "# ✅ Train base logistic regression model\n",
        "%%bigquery --project $project_id\n",
        "CREATE OR REPLACE MODEL `your_dataset.churn_model`\n",
        "OPTIONS(model_type='logistic_reg') AS\n",
        "SELECT\n",
        "  region,\n",
        "  plan_tier,\n",
        "  age_band,\n",
        "  avg_rating,\n",
        "  total_minutes,\n",
        "  avg_progress,\n",
        "  num_sessions,\n",
        "  churn_label\n",
        "FROM `your_dataset.churn_features`;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69fc3475",
      "metadata": {
        "id": "69fc3475"
      },
      "outputs": [],
      "source": [
        "# ✅ Evaluate base model\n",
        "%%bigquery --project $project_id\n",
        "SELECT *\n",
        "FROM ML.EVALUATE(MODEL `your_dataset.churn_model`);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddceee25",
      "metadata": {
        "collapsed": true,
        "id": "ddceee25"
      },
      "outputs": [],
      "source": [
        "# ✅ Predict churn with base model\n",
        "%%bigquery --project $project_id\n",
        "SELECT\n",
        "  user_id,\n",
        "  predicted_churn_label,\n",
        "  predicted_churn_label_probs\n",
        "FROM ML.PREDICT(MODEL `your_dataset.churn_model`,\n",
        "                (SELECT * FROM `your_dataset.churn_features`));"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3718b255",
      "metadata": {
        "id": "3718b255"
      },
      "source": [
        "\n",
        "## 🛠️ Feature Engineering Section\n",
        "\n",
        "We will now engineer new features to improve model performance:\n",
        "\n",
        "- Bucket continuous variables\n",
        "- Create interaction terms\n",
        "- Add behavioral flags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "272f675d",
      "metadata": {
        "id": "272f675d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ✅ Create enhanced feature set\n",
        "%%bigquery --project $project_id\n",
        "CREATE OR REPLACE TABLE `your_dataset.churn_features_enhanced` AS\n",
        "SELECT\n",
        "  user_id,\n",
        "  region,\n",
        "  plan_tier,\n",
        "  age_band,\n",
        "  avg_rating,\n",
        "  total_minutes,\n",
        "  CASE\n",
        "    WHEN total_minutes < 100 THEN 'low'\n",
        "    WHEN total_minutes BETWEEN 100 AND 300 THEN 'medium'\n",
        "    ELSE 'high'\n",
        "  END AS watch_time_bucket,\n",
        "  avg_progress,\n",
        "  num_sessions,\n",
        "  CONCAT(plan_tier, '_', region) AS plan_region_combo,\n",
        "  IF(total_minutes > 500, 1, 0) AS flag_binge,\n",
        "  churn_label\n",
        "FROM `your_dataset.churn_features`;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07d70fe5",
      "metadata": {
        "id": "07d70fe5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ✅ Train enhanced model\n",
        "%%bigquery --project $project_id\n",
        "CREATE OR REPLACE MODEL `your_dataset.churn_model_enhanced`\n",
        "OPTIONS(model_type='logistic_reg') AS\n",
        "SELECT\n",
        "  region,\n",
        "  plan_tier,\n",
        "  age_band,\n",
        "  watch_time_bucket,\n",
        "  avg_rating,\n",
        "  avg_progress,\n",
        "  num_sessions,\n",
        "  plan_region_combo,\n",
        "  flag_binge,\n",
        "  churn_label\n",
        "FROM `your_dataset.churn_features_enhanced`;\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "423b6d00",
      "metadata": {
        "id": "423b6d00"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ✅ Evaluate enhanced model\n",
        "%%bigquery --project $project_id\n",
        "SELECT *\n",
        "FROM ML.EVALUATE(MODEL `your_dataset.churn_model_enhanced`);\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc1a207f",
      "metadata": {
        "id": "bc1a207f"
      },
      "source": [
        "\n",
        "## 🤔 Chain-of-Thought Prompts: Feature Engineering\n",
        "\n",
        "### 1. Why bucket continuous values like watch time?\n",
        "- What patterns become clearer by using categories like \"low\", \"medium\", \"high\"?\n",
        "\n",
        "**Bucketing watch time into ranges like “low,” “medium,” and “high” makes it easier to spot patterns that aren’t always obvious from the raw numbers. For example, users with really low watch time might be at risk of churning because they’re not engaged, while those in the high range are probably loyal and active. It also helps the model separate user groups more clearly instead of assuming the relationship is linear.**\n",
        "\n",
        "### 2. What value do interaction terms (e.g., `plan_tier_region`) add?\n",
        "- Could some plans behave differently in different regions?\n",
        "\n",
        "**Interaction terms let the model look at how different factors work together instead of separately. Some plans might perform differently depending on the region — for instance, a “Standard” plan could retain users well in one area but not in another. By combining both variables, we capture that joint effect and give the model more context.**\n",
        "\n",
        "### 3. What’s the purpose of binary flags like `flag_binge`?\n",
        "- Can these capture unique behaviors not reflected in raw totals?\n",
        "\n",
        "**Binary flags highlight unique behaviors that might not show up in the main metrics. For example, the flag_binge column (where 1 means total_minutes > 500) helps identify heavy users who watch a lot of content. Those users are likely to stay subscribed longer, so it adds another dimension that pure totals might miss.**\n",
        "\n",
        "### 4. After evaluating the enhanced model:\n",
        "- Which new features helped the most?\n",
        "- Did any surprise you?\n",
        "\n",
        "**After retraining, the enhanced model performed a bit better overall, especially in precision and ROC AUC. The biggest difference seemed to come from the new flag_binge feature, which makes sense since binge-watching is usually tied to higher engagement. The improvement wasn’t huge, but it showed that these new features did add some predictive power and helped the model understand user behavior a little more deeply.**\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}